# üìÅ Desafio Kinetic - Procesamiento de Archivos TXT en Lotes

## üìå Enfoque y Decisiones de Dise√±o

Este proyecto fue dise√±ado como una API RESTful construida en **ASP.NET Core 8**, con **Hangfire** para la ejecuci√≥n en segundo plano de procesos batch. El sistema procesa archivos `.txt` en carpetas, extrayendo estad√≠sticas y generando res√∫menes autom√°ticos de su contenido.

### Decisiones clave:

- ‚úÖ **Hangfire** permite manejar trabajos en segundo plano de forma escalable y desacoplada.
- ‚úÖ Se us√≥ **ProcessStateStore** para persistencia local y resiliencia simple mediante archivos JSON.
- ‚úÖ El procesamiento es **independiente** por carpeta, lo que facilita reinicios seguros.
- ‚úÖ La l√≥gica del negocio se encuentra en `FolderProcessor`, con separaci√≥n clara de responsabilidades.

---

## üõ†Ô∏è Instalaci√≥n y Uso

### ‚úÖ Requisitos previos

- [.NET 8 SDK](https://dotnet.microsoft.com/en-us/download)
- [Docker](https://www.docker.com/) (opcional)
- Hangfire Dashboard (opcional)


### üöÄ Ejecuci√≥n Docker

```bash
# Clonar el proyecto
git clone https://github.com/javierserra/Desafio_Kinetic.git
cd Desafio_Kinetic

# Ejecutar
docker compose -f docker-compose.yml up -d --build 
```


-  El API estar√° disponible en: `http://localhost:8080`
-  La documentaci√≥n Swagger UI estar√° disponible en: `http://localhost:8080/swagger`
-  El monitoreo del servicio Hangfire estar√° disponible en: `http://localhost:8080/hangfire`

### üß™ Prueba del procesamiento

1. Crea una estructura con subcarpetas en `/app/input` y coloca archivos `.txt` en ellas. El repo original cuanta con carpetas y archivos de prueba en la ruta indicada.
2. Ejecuta un `POST` a `http://localhost:8080/api/processes` con:

```json
{
  "rootPath": "/app/input"
}
```

3. Consulta el estado y resultado:

- `GET /api/processes/{id}/status`
- `GET /api/processes/{id}/result`

---

## üîÅ Estrategia de Resiliencia

### üîÑ ¬øQu√© sucede si la aplicaci√≥n se reinicia?

- El estado de cada proceso se guarda en disco (`state.json`), por lo que al reiniciar, los procesos ya ejecutados no se pierden.
- Se puede consultar el estado de todos los procesos a√∫n despu√©s del reinicio.

### ‚ùå ¬øY si un archivo est√° corrupto?

- El sistema atrapa excepciones durante el procesamiento individual.
- El archivo es marcado como `"FAILED"` y el resto del lote contin√∫a.
- El estado del proceso puede quedar como `"FAILED"` si al menos un archivo falla.
- A√∫n es posible agregar gesti√≥n de diversos errores. Se considera apropiado este nivel para el MVP
---

## üß± Arquitectura Futura. 

### 1Ô∏è‚É£ Escalabilidad

Para procesar millones de documentos al d√≠a desde m√∫ltiples fuentes:

**Cambio 1: Desacoplar procesamiento por colas**
- Reemplazar `Hangfire` por colas distribuidas como **AWS SQS**, **RabbitMQ** o **Kafka** para distribuir el trabajo en m√∫ltiples workers.

**Cambio 2: Almacenamiento en nube**
- Migrar `ProcessStateStore` y `GenDocs` a almacenamiento persistente o temporal como **DynamoDB**, **Redis** o **MongoDB Atlas**.

**Cambio 3: Workers distribuidos y autoscaling**
- Generar COntenedores y escalar los workers (`FolderProcessor`) horizontalmente en un orquestador como Kubernetes.

---

### 2Ô∏è‚É£ Infraestructura Recomendada. Menciono los servicios de AWS, pero encontrar√°n equivalentes en otros Clouds.

| Recurso | Justificaci√≥n |
|--------|----------------|
| **AWS Lambda / ECS Fargate** | Serverless o contenedores autogestionados para ejecutar los workers por lote |
| **S3** | Para almacenar archivos de entrada y salidas JSON |
| **DynamoDB o MongoDB Atlas** | Para almacenar estados y resultados de procesos |
| **SQS** | Para orquestar eventos de carpetas nuevas o archivos nuevos |
| **CloudWatch / OpenTelemetry / Loki-Grafana** | Monitoreo y trazabilidad de procesos |

---

## üß™ Instrucciones para pruebas

### ‚úÖ Pruebas manuales

- Ejecutar el servicio sobre un contendor.
- Cargar archivos `.txt` en carpetas en la ruta que defina el mapeo.
- Usar herramientas como Postman o curl para probar los endpoints:
  - `POST /api/processes`
  - `GET /api/processes/{id}/status`
  - `GET /api/processes/{id}/result`

---

## üìö Documentaci√≥n OpenAPI

El proyecto est√° autodocumentado con Swagger. Accede a la documentaci√≥n navegando a:

```
http://localhost:8080/swagger
```

Incluye:

- Descripci√≥n de cada endpoint.
- Ejemplos de entrada y salida.
- C√≥digos de estado esperados.


## üìö Utilizaci√≥n de AI

No tengo mucha experiencia (al menos en los √∫ltmos a√±os) en el desarrollo sobre .NET, por lo que gran parte del c√≥digo fu√© etructurado desde las siguientes consulta a ChatGPT y GeminiAI seg√πn el caso. Los test por ejemplo son completamente generados por AI:

```
PROMPT 1:
En .NET tengo que ejecutar y administrar un proceso as√≠ncrono que ser√° iniciado desde un endpoint, y desde otros pausado, verificado status y resoluci√≥n. Que librer√≠as me recomiendan para administrar este tipo proceso?

De las 4 posibilidades ofrecidas se elige Hangfire que est√° dise√±ada espec√≠ficamente para tratamiento en Batch y presenta un tablero de monitoreo propio como plus a la soluci√≥n.

Como no conozco la soluci√≥n, pido a la  AI un ejemplo de c√≥mo implementar esta librer√≠a en una API .NET con una arquitectura de capas separando servicios de controllers y models 
PROMPT 2:
Por favor, dame un ejemplo de c√≥mo implementar Hangfire en una API con un namespace services donde residir√°n cada una de las acciones sobre una estructura de archivos inferida de un path a procesar, iniciando un job por cada subcarpeta del path.

El resultado obtenido se usa como base para iniciar el desarrollo y subo un primer commit funcional a github para ir registrando el avance.
Para no avanzar m√°s sin agregar logging, consulto sobre el ejemplo:

PROMPT 3:
C√≥mo aplicar un login estructurado a este c√≥digo?
Adapto la respuesta del chat y lo subo al repo en un segundo commit. 


PROMPT 4:
Hola, quisiera que me ayudes a construir una lista predefinida en castellano de stop_words comunes como "el", "la", "que", "y", "a", etc.


PROMPT 5:
Hola, quisiera que me orientaras en c√≥mo generar una persistencia de un diccionario JSON que pueda ser utilizado por distintos endpoints de mi API c# para mantener un proceso stateful ‚óè PENDING: Proceso creado pero no iniciado. ‚óè RUNNING: Procesamiento en curso. ‚óè PAUSED: Proceso pausado temporalmente. ‚óè COMPLETED: Proceso finalizado con √©xito. ‚óè FAILED: Proceso terminado con errores. ‚óè STOPPED: Proceso detenido manualmente.
El resultado obtenido se usa como base para desarrollar la persistencia de los estados y los resultados en procesos paralelos y se realiza commit

PROMPT 6:
Hola, tengo un sistema que hace un procesamiento por lotes de archivos con el siguiente requisito funcional Extraer estad√≠sticas b√°sicas: conteo de palabras, l√≠neas y caracteres. Identificar las 10 palabras m√°s frecuentes (excluyendo "stop words" comunes como "el","la", "que", "y", "a", etc. Puedes usar una lista predefinida).Generar un resumen de contenido simple con saltos de l√≠nea (ej. tomando las primeras 3-4 oraciones del documento). Me gustar√≠a que generes una carpeta con 3 lotes y 10 archivos en cada uno en un archivo zip que pueda descargar. cada archivo debe tener contenido real en castellano variado (m√≠nimo 500 palabras cada uno) para demostrar la funcionalidad del sistema.

PROMPT 7:
hola, tengo que leer estos archivos en c# y generar un resumen de su contenido. ¬øc√≥mo podr√≠a generar este contenido resumen?

```
